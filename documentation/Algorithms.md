# Algorithms
## Stitching Overview
In order to perform image stitching of various images from different viewpoints, we must first identify the various keypoints in the different images. Keypoints are points which are interesting in the image, these are corners, edges or blobs which are different from the the pixels surrounding them making them distinct. Once the keypoints are detected, the next step involves identifying the various descriptors. Descriptors are compact representations of the local neighborhood around each keypoint in an image. While keypoints provide the location of distinctive points, descriptors encode information about the appearance or gradient distribution of pixels in the vicinity of each keypoint. Once we do this for each image, the next step involves matching the features which are similar in the different images. Not every matches are accurate, we use RANSAC algorithm to remove any outliers. Once the matching of keypoints between images is completed, the next step in image stitching is to compute the homography matrix. The homography matrix is a transformation matrix that describes the mapping between two perspective views of the same scene. This matrix is determined by the matching we did earlier and tells us what transformation must be done to convert one image's descriptor and keypoint into the another image. Using this homology matrix we warp one image and superimpose the other image on this to get the stitched image. Finally we blend the overlaps to remove the seam.

## ORB Overview
We have used ORB(Oriented FAST and Rotated BRIEF) for the detection of keypoints and descriptors. ORB effectively combines FAST and BRIEF algorithm and provides results twice as fast and accurate as SIFT and SURF. FAST (Features from Accelerated Segment Test) works as follow:
1. The algorithm iterates for all the pixels in the array.
2. The algorithm considers a circle of radius 3 around it and every pixel the circle touches is stored in an array.
3. If there are 12 contigous pixels in the circle (array) which are either greater than I + threshold or less than I - threshold, then that point is considered a keypoint.( I is the intensity of the current pixel and the threshold is normally 0.2 * I).
FAST is scale invariant, therefore to overcome this limitation, we apply FAST to the scaled down images of the current image. Once we find the keypoints from the various resolutions, we can then keep the keypoints which are common in all the scales and decide the direction of the keypoint using moments of that feature.
BRIEF ()

## Feature Matching Overview
There are two types of algorithm for feature matching, FLANN and BruteForce. We tested both these algorithms and decided to choose BruteForce as it gives the best matches. Brute force matching is more robust to variations in the dataset and descriptors. FLANN's approximation techniques may not handle all types of descriptorsvery well, particularly with binary descriptors like those generated by ORB. BruteForce works by works by exhaustively comparing each feature descriptor in one set with all feature descriptors in another set to find the closest matches. For BruteForce we use NORM_HAMMING, it calculates the Hamming distance between two binary strings, which represents the number of bits that differ between the two strings. This is best suited for ORB since BRIEF produces descriptors which are binary strings.

